{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:15.916231611Z",
     "start_time": "2024-07-30T17:03:14.076007272Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n\n  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n0         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n1         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n2         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n3         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n4         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n\n  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n0       0      2    2008        WD         Normal  \n1       0      5    2007        WD         Normal  \n2       0      9    2008        WD         Normal  \n3       0      2    2006        WD        Abnorml  \n4       0     12    2008        WD         Normal  \n\n[5 rows x 80 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 80 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "y = data['SalePrice']\n",
    "X = data.drop('SalePrice', axis=1)\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:15.978815732Z",
     "start_time": "2024-07-30T17:03:15.916527537Z"
    }
   },
   "id": "3f375d6aeed3e16c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n0   1          60         65.0     8450            7            5       2003   \n1   2          20         80.0     9600            6            8       1976   \n2   3          60         68.0    11250            7            5       2001   \n3   4          70         60.0     9550            7            5       1915   \n4   5          60         84.0    14260            8            5       2000   \n\n   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  GarageArea  WoodDeckSF  \\\n0          2003       196.0         706  ...         548           0   \n1          1976         0.0         978  ...         460         298   \n2          2002       162.0         486  ...         608           0   \n3          1970         0.0         216  ...         642           0   \n4          2000       350.0         655  ...         836         192   \n\n   OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n0           61              0          0            0         0        0   \n1            0              0          0            0         0        0   \n2           42              0          0            0         0        0   \n3           35            272          0            0         0        0   \n4           84              0          0            0         0        0   \n\n   MoSold  YrSold  \n0       2    2008  \n1       5    2007  \n2       9    2008  \n3       2    2006  \n4      12    2008  \n\n[5 rows x 37 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196.0</td>\n      <td>706</td>\n      <td>...</td>\n      <td>548</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0.0</td>\n      <td>978</td>\n      <td>...</td>\n      <td>460</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162.0</td>\n      <td>486</td>\n      <td>...</td>\n      <td>608</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>216</td>\n      <td>...</td>\n      <td>642</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350.0</td>\n      <td>655</td>\n      <td>...</td>\n      <td>836</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 37 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.drop('Id', axis=1)\n",
    "numeric_cols = list(X.select_dtypes(include=np.number).columns)\n",
    "X_num = X[numeric_cols]\n",
    "X_num.columns = X[numeric_cols].columns\n",
    "X_num.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:15.982275095Z",
     "start_time": "2024-07-30T17:03:15.961374804Z"
    }
   },
   "id": "f93d42995bc3b2a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First model will use only numeric values and missing values will be imputed with SimpleImputer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7196d8b03b3bd0e1"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_imputer = SimpleImputer()\n",
    "\n",
    "def get_train_test_data(X, y, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "    imputed_X_test = pd.DataFrame(my_imputer.transform(X_test))\n",
    "    \n",
    "    imputed_X_train.columns = X_train.columns\n",
    "    imputed_X_test.columns = X_test.columns\n",
    "    \n",
    "    X_train, X_test = imputed_X_train, imputed_X_test\n",
    "    \n",
    "    X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.values, dtype=torch.float32).squeeze()\n",
    "    y_test = torch.tensor(y_test.values, dtype=torch.float32).squeeze()\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:16.208107330Z",
     "start_time": "2024-07-30T17:03:15.980946855Z"
    }
   },
   "id": "6abb294b85f240c3"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_data(X_num, y, test_size=0.2)\n",
    "X_num = pd.DataFrame(my_imputer.transform(X_num))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:16.239231672Z",
     "start_time": "2024-07-30T17:03:16.058217600Z"
    }
   },
   "id": "1430845137a86db"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class ModelV1(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=in_features, out_features=1),\n",
    "            # nn.Linear(in_features=10, out_features=10),\n",
    "            # nn.Linear(in_features=10, out_features=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:16.251455790Z",
     "start_time": "2024-07-30T17:03:16.086073461Z"
    }
   },
   "id": "f33340deaf7665f7"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model1 = ModelV1(in_features=37)\n",
    "\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(params=model1.parameters(), lr=0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:16.709752090Z",
     "start_time": "2024-07-30T17:03:16.092681776Z"
    }
   },
   "id": "cfa7ae65ba16ce"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ -474.0264,  -650.4340,  -734.6797,  ...,  -835.0174,  -503.3602,\n        -1073.6823], grad_fn=<SqueezeBackward0>)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()\n",
    "y_pred = model1(X_train).squeeze()\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:16.740208771Z",
     "start_time": "2024-07-30T17:03:16.717442844Z"
    }
   },
   "id": "1534193b0b21b3c5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def train_test(model:torch.nn.Module, loss_fn:torch.nn.Module, optimizer:torch.optim.Optimizer, epochs:int, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        y_preds = model(X_train).squeeze()\n",
    "        loss = loss_fn(y_preds, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with (torch.inference_mode()):\n",
    "            test_pred = model(X_test).squeeze()\n",
    "            test_loss = loss_fn(test_pred, y_test)\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"----------------------------\")\n",
    "            print(f\"Epoch {epoch}:\")\n",
    "            print(f\"Train loss: {loss} | Test loss: {test_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:16.741178916Z",
     "start_time": "2024-07-30T17:03:16.719895863Z"
    }
   },
   "id": "99076809838fcd50"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Epoch 0:\n",
      "Train loss: 181759.0625 | Test loss: 167535.671875\n",
      "----------------------------\n",
      "Epoch 50:\n",
      "Train loss: 61975.453125 | Test loss: 49551.8828125\n",
      "----------------------------\n",
      "Epoch 100:\n",
      "Train loss: 57334.12890625 | Test loss: 46591.12109375\n",
      "----------------------------\n",
      "Epoch 150:\n",
      "Train loss: 53421.984375 | Test loss: 44410.29296875\n",
      "----------------------------\n",
      "Epoch 200:\n",
      "Train loss: 50357.42578125 | Test loss: 43212.046875\n",
      "----------------------------\n",
      "Epoch 250:\n",
      "Train loss: 48113.765625 | Test loss: 42274.8359375\n",
      "----------------------------\n",
      "Epoch 300:\n",
      "Train loss: 46456.4921875 | Test loss: 41690.92578125\n",
      "----------------------------\n",
      "Epoch 350:\n",
      "Train loss: 45199.046875 | Test loss: 41291.29296875\n",
      "----------------------------\n",
      "Epoch 400:\n",
      "Train loss: 44108.54296875 | Test loss: 40899.99609375\n",
      "----------------------------\n",
      "Epoch 450:\n",
      "Train loss: 43169.12890625 | Test loss: 40496.234375\n",
      "----------------------------\n",
      "Epoch 500:\n",
      "Train loss: 42391.23828125 | Test loss: 40068.1640625\n",
      "----------------------------\n",
      "Epoch 550:\n",
      "Train loss: 41770.35546875 | Test loss: 39680.9765625\n",
      "----------------------------\n",
      "Epoch 600:\n",
      "Train loss: 41196.04296875 | Test loss: 39330.5078125\n",
      "----------------------------\n",
      "Epoch 650:\n",
      "Train loss: 40653.34765625 | Test loss: 38963.2265625\n",
      "----------------------------\n",
      "Epoch 700:\n",
      "Train loss: 40138.23046875 | Test loss: 38580.2734375\n",
      "----------------------------\n",
      "Epoch 750:\n",
      "Train loss: 39637.59765625 | Test loss: 38176.7734375\n",
      "----------------------------\n",
      "Epoch 800:\n",
      "Train loss: 39149.6796875 | Test loss: 37776.84375\n",
      "----------------------------\n",
      "Epoch 850:\n",
      "Train loss: 38678.8046875 | Test loss: 37397.109375\n",
      "----------------------------\n",
      "Epoch 900:\n",
      "Train loss: 38215.54296875 | Test loss: 37042.8515625\n",
      "----------------------------\n",
      "Epoch 950:\n",
      "Train loss: 37764.6015625 | Test loss: 36694.99609375\n",
      "----------------------------\n",
      "Epoch 1000:\n",
      "Train loss: 37325.8515625 | Test loss: 36360.05859375\n",
      "----------------------------\n",
      "Epoch 1050:\n",
      "Train loss: 36902.61328125 | Test loss: 36040.04296875\n",
      "----------------------------\n",
      "Epoch 1100:\n",
      "Train loss: 36503.29296875 | Test loss: 35745.4765625\n",
      "----------------------------\n",
      "Epoch 1150:\n",
      "Train loss: 36119.95703125 | Test loss: 35459.43359375\n",
      "----------------------------\n",
      "Epoch 1200:\n",
      "Train loss: 35753.1015625 | Test loss: 35172.25390625\n",
      "----------------------------\n",
      "Epoch 1250:\n",
      "Train loss: 35395.37109375 | Test loss: 34892.18359375\n",
      "----------------------------\n",
      "Epoch 1300:\n",
      "Train loss: 35053.9375 | Test loss: 34615.015625\n",
      "----------------------------\n",
      "Epoch 1350:\n",
      "Train loss: 34732.77734375 | Test loss: 34354.27734375\n",
      "----------------------------\n",
      "Epoch 1400:\n",
      "Train loss: 34419.98828125 | Test loss: 34100.67578125\n",
      "----------------------------\n",
      "Epoch 1450:\n",
      "Train loss: 34123.84765625 | Test loss: 33855.546875\n",
      "----------------------------\n",
      "Epoch 1500:\n",
      "Train loss: 33850.3203125 | Test loss: 33621.7109375\n",
      "----------------------------\n",
      "Epoch 1550:\n",
      "Train loss: 33589.60546875 | Test loss: 33398.23046875\n",
      "----------------------------\n",
      "Epoch 1600:\n",
      "Train loss: 33332.828125 | Test loss: 33181.0546875\n",
      "----------------------------\n",
      "Epoch 1650:\n",
      "Train loss: 33089.19140625 | Test loss: 32984.1953125\n",
      "----------------------------\n",
      "Epoch 1700:\n",
      "Train loss: 32856.71484375 | Test loss: 32779.58203125\n",
      "----------------------------\n",
      "Epoch 1750:\n",
      "Train loss: 32634.236328125 | Test loss: 32591.591796875\n",
      "----------------------------\n",
      "Epoch 1800:\n",
      "Train loss: 32424.4453125 | Test loss: 32404.826171875\n",
      "----------------------------\n",
      "Epoch 1850:\n",
      "Train loss: 32218.38671875 | Test loss: 32201.63671875\n",
      "----------------------------\n",
      "Epoch 1900:\n",
      "Train loss: 32026.41015625 | Test loss: 32022.712890625\n",
      "----------------------------\n",
      "Epoch 1950:\n",
      "Train loss: 31852.19140625 | Test loss: 31846.13671875\n"
     ]
    }
   ],
   "source": [
    "train_test(model=model1, loss_fn=loss_fn, optimizer=optimizer, epochs=2000, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:17.993524732Z",
     "start_time": "2024-07-30T17:03:16.721374666Z"
    }
   },
   "id": "cf68177afdf2c915"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This results are not great, let's figure out which 5 data columns have the most corelation with SalePrice and use only them"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86fb12508d61e8e5"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:18.006994008Z",
     "start_time": "2024-07-30T17:03:17.989411899Z"
    }
   },
   "id": "e8e7e783399b8c90"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "4     0.563859\n16    0.481432\n12    0.368610\n27    0.359944\n6     0.357934\n26    0.354998\n13    0.309227\nName: MI Scores, dtype: float64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_features = X_num.dtypes == int\n",
    "\n",
    "mi_scores = make_mi_scores(X_num, y, discrete_features=discrete_features)\n",
    "mi_scores[:7]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:18.198381007Z",
     "start_time": "2024-07-30T17:03:18.001191503Z"
    }
   },
   "id": "2e7b7d286e2e9220"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's now use only this 7 features in a Model and see if there is any difference in performance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d35d8f0f804fcc5"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model2 = ModelV1(in_features=7)\n",
    "lista = list(mi_scores[:7].index)\n",
    "for i in lista:\n",
    "    i -= 1\n",
    "X_num_2 = X_num[lista]\n",
    "X_train, X_test, y_train, y_test = get_train_test_data(X_num_2, y, test_size=0.2)\n",
    "optimizer_2 = torch.optim.SGD(params=model2.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:18.212038126Z",
     "start_time": "2024-07-30T17:03:18.201172837Z"
    }
   },
   "id": "669c09d2f00993d0"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Epoch 0:\n",
      "Train loss: 183140.328125 | Test loss: 165394.46875\n",
      "----------------------------\n",
      "Epoch 50:\n",
      "Train loss: 38650.90625 | Test loss: 37497.1171875\n",
      "----------------------------\n",
      "Epoch 100:\n",
      "Train loss: 36891.08984375 | Test loss: 35779.34375\n",
      "----------------------------\n",
      "Epoch 150:\n",
      "Train loss: 35508.72265625 | Test loss: 34315.71875\n",
      "----------------------------\n",
      "Epoch 200:\n",
      "Train loss: 34434.8828125 | Test loss: 33131.171875\n",
      "----------------------------\n",
      "Epoch 250:\n",
      "Train loss: 33569.90625 | Test loss: 32203.740234375\n",
      "----------------------------\n",
      "Epoch 300:\n",
      "Train loss: 32845.20703125 | Test loss: 31391.423828125\n",
      "----------------------------\n",
      "Epoch 350:\n",
      "Train loss: 32299.798828125 | Test loss: 30840.66796875\n",
      "----------------------------\n",
      "Epoch 400:\n",
      "Train loss: 31864.28125 | Test loss: 30444.599609375\n",
      "----------------------------\n",
      "Epoch 450:\n",
      "Train loss: 31513.61328125 | Test loss: 30128.5078125\n",
      "----------------------------\n",
      "Epoch 500:\n",
      "Train loss: 31223.94921875 | Test loss: 29951.544921875\n",
      "----------------------------\n",
      "Epoch 550:\n",
      "Train loss: 30971.158203125 | Test loss: 29795.30078125\n",
      "----------------------------\n",
      "Epoch 600:\n",
      "Train loss: 30758.25390625 | Test loss: 29687.376953125\n",
      "----------------------------\n",
      "Epoch 650:\n",
      "Train loss: 30581.28515625 | Test loss: 29561.2421875\n",
      "----------------------------\n",
      "Epoch 700:\n",
      "Train loss: 30435.64453125 | Test loss: 29506.25\n",
      "----------------------------\n",
      "Epoch 750:\n",
      "Train loss: 30317.35546875 | Test loss: 29452.71484375\n",
      "----------------------------\n",
      "Epoch 800:\n",
      "Train loss: 30214.1875 | Test loss: 29392.11328125\n",
      "----------------------------\n",
      "Epoch 850:\n",
      "Train loss: 30119.9765625 | Test loss: 29325.53515625\n",
      "----------------------------\n",
      "Epoch 900:\n",
      "Train loss: 30030.10546875 | Test loss: 29238.69140625\n",
      "----------------------------\n",
      "Epoch 950:\n",
      "Train loss: 29948.517578125 | Test loss: 29187.791015625\n",
      "----------------------------\n",
      "Epoch 1000:\n",
      "Train loss: 29877.16796875 | Test loss: 29139.091796875\n",
      "----------------------------\n",
      "Epoch 1050:\n",
      "Train loss: 29812.3828125 | Test loss: 29071.9921875\n",
      "----------------------------\n",
      "Epoch 1100:\n",
      "Train loss: 29752.873046875 | Test loss: 29040.171875\n",
      "----------------------------\n",
      "Epoch 1150:\n",
      "Train loss: 29700.041015625 | Test loss: 28986.44921875\n",
      "----------------------------\n",
      "Epoch 1200:\n",
      "Train loss: 29649.603515625 | Test loss: 28936.36328125\n",
      "----------------------------\n",
      "Epoch 1250:\n",
      "Train loss: 29602.931640625 | Test loss: 28891.3671875\n",
      "----------------------------\n",
      "Epoch 1300:\n",
      "Train loss: 29560.578125 | Test loss: 28841.828125\n",
      "----------------------------\n",
      "Epoch 1350:\n",
      "Train loss: 29519.00390625 | Test loss: 28818.728515625\n",
      "----------------------------\n",
      "Epoch 1400:\n",
      "Train loss: 29478.701171875 | Test loss: 28771.923828125\n",
      "----------------------------\n",
      "Epoch 1450:\n",
      "Train loss: 29444.4375 | Test loss: 28753.63671875\n",
      "----------------------------\n",
      "Epoch 1500:\n",
      "Train loss: 29412.541015625 | Test loss: 28733.7421875\n",
      "----------------------------\n",
      "Epoch 1550:\n",
      "Train loss: 29382.677734375 | Test loss: 28717.78515625\n",
      "----------------------------\n",
      "Epoch 1600:\n",
      "Train loss: 29354.591796875 | Test loss: 28692.443359375\n",
      "----------------------------\n",
      "Epoch 1650:\n",
      "Train loss: 29328.66796875 | Test loss: 28677.2265625\n",
      "----------------------------\n",
      "Epoch 1700:\n",
      "Train loss: 29303.14453125 | Test loss: 28647.6796875\n",
      "----------------------------\n",
      "Epoch 1750:\n",
      "Train loss: 29279.353515625 | Test loss: 28627.412109375\n",
      "----------------------------\n",
      "Epoch 1800:\n",
      "Train loss: 29257.13671875 | Test loss: 28619.654296875\n",
      "----------------------------\n",
      "Epoch 1850:\n",
      "Train loss: 29236.951171875 | Test loss: 28604.8359375\n",
      "----------------------------\n",
      "Epoch 1900:\n",
      "Train loss: 29216.91015625 | Test loss: 28600.5078125\n",
      "----------------------------\n",
      "Epoch 1950:\n",
      "Train loss: 29198.599609375 | Test loss: 28599.490234375\n"
     ]
    }
   ],
   "source": [
    "train_test(model=model2, loss_fn=loss_fn, optimizer=optimizer_2, epochs=2000, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:18.796805505Z",
     "start_time": "2024-07-30T17:03:18.209373407Z"
    }
   },
   "id": "84eeee795b86b4c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now let's try to normalize data and see whether it improves our result or not"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0109b661b6b2c0c"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "X_num_3 = X_num_2\n",
    "y_normalized = pd.DataFrame(torch.nn.functional.normalize(torch.tensor(y, dtype=torch.float32).unsqueeze(dim=1)))\n",
    "X_train, X_test, y_train, y_test = get_train_test_data(X_num_3, y_normalized, test_size=0.2)\n",
    "X_train, X_test = torch.nn.functional.normalize(X_train), torch.nn.functional.normalize(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:18.797263280Z",
     "start_time": "2024-07-30T17:03:18.787592980Z"
    }
   },
   "id": "35286dbc2acaba91"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "model3 = ModelV1(in_features=7)\n",
    "optimizer_3 = torch.optim.SGD(params=model3.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:18.809385101Z",
     "start_time": "2024-07-30T17:03:18.797014092Z"
    }
   },
   "id": "2a561fb63a6745c0"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Epoch 0:\n",
      "Train loss: 0.485415518283844 | Test loss: 0.4867783188819885\n",
      "----------------------------\n",
      "Epoch 50:\n",
      "Train loss: 0.38735586404800415 | Test loss: 0.3886602222919464\n",
      "----------------------------\n",
      "Epoch 100:\n",
      "Train loss: 0.28929615020751953 | Test loss: 0.2905420660972595\n",
      "----------------------------\n",
      "Epoch 150:\n",
      "Train loss: 0.1912364661693573 | Test loss: 0.19242393970489502\n",
      "----------------------------\n",
      "Epoch 200:\n",
      "Train loss: 0.09317672997713089 | Test loss: 0.09430575370788574\n",
      "----------------------------\n",
      "Epoch 250:\n",
      "Train loss: 0.031522758305072784 | Test loss: 0.030014952644705772\n",
      "----------------------------\n",
      "Epoch 300:\n",
      "Train loss: 0.02891691029071808 | Test loss: 0.025968892499804497\n",
      "----------------------------\n",
      "Epoch 350:\n",
      "Train loss: 0.02837458997964859 | Test loss: 0.025271162390708923\n",
      "----------------------------\n",
      "Epoch 400:\n",
      "Train loss: 0.027866709977388382 | Test loss: 0.02476171962916851\n",
      "----------------------------\n",
      "Epoch 450:\n",
      "Train loss: 0.027361778542399406 | Test loss: 0.024282976984977722\n",
      "----------------------------\n",
      "Epoch 500:\n",
      "Train loss: 0.026860717684030533 | Test loss: 0.023808278143405914\n",
      "----------------------------\n",
      "Epoch 550:\n",
      "Train loss: 0.026361670345067978 | Test loss: 0.02334359660744667\n",
      "----------------------------\n",
      "Epoch 600:\n",
      "Train loss: 0.02586282044649124 | Test loss: 0.022883368656039238\n",
      "----------------------------\n",
      "Epoch 650:\n",
      "Train loss: 0.0253708865493536 | Test loss: 0.022403981536626816\n",
      "----------------------------\n",
      "Epoch 700:\n",
      "Train loss: 0.024882333353161812 | Test loss: 0.02194826304912567\n",
      "----------------------------\n",
      "Epoch 750:\n",
      "Train loss: 0.024394191801548004 | Test loss: 0.021504554897546768\n",
      "----------------------------\n",
      "Epoch 800:\n",
      "Train loss: 0.02390921115875244 | Test loss: 0.021067721769213676\n",
      "----------------------------\n",
      "Epoch 850:\n",
      "Train loss: 0.023425182327628136 | Test loss: 0.020624827593564987\n",
      "----------------------------\n",
      "Epoch 900:\n",
      "Train loss: 0.02294115349650383 | Test loss: 0.020181935280561447\n",
      "----------------------------\n",
      "Epoch 950:\n",
      "Train loss: 0.022459376603364944 | Test loss: 0.01973949559032917\n",
      "----------------------------\n",
      "Epoch 1000:\n",
      "Train loss: 0.021978650242090225 | Test loss: 0.019316401332616806\n",
      "----------------------------\n",
      "Epoch 1050:\n",
      "Train loss: 0.021499650552868843 | Test loss: 0.018891550600528717\n",
      "----------------------------\n",
      "Epoch 1100:\n",
      "Train loss: 0.021021001040935516 | Test loss: 0.01845249906182289\n",
      "----------------------------\n",
      "Epoch 1150:\n",
      "Train loss: 0.02054315060377121 | Test loss: 0.0180208757519722\n",
      "----------------------------\n",
      "Epoch 1200:\n",
      "Train loss: 0.02006770670413971 | Test loss: 0.01758940890431404\n",
      "----------------------------\n",
      "Epoch 1250:\n",
      "Train loss: 0.01959725096821785 | Test loss: 0.01717035099864006\n",
      "----------------------------\n",
      "Epoch 1300:\n",
      "Train loss: 0.019129477441310883 | Test loss: 0.016754884272813797\n",
      "----------------------------\n",
      "Epoch 1350:\n",
      "Train loss: 0.01866826042532921 | Test loss: 0.01634286530315876\n",
      "----------------------------\n",
      "Epoch 1400:\n",
      "Train loss: 0.01820947416126728 | Test loss: 0.01594335213303566\n",
      "----------------------------\n",
      "Epoch 1450:\n",
      "Train loss: 0.017751360312104225 | Test loss: 0.015542578883469105\n",
      "----------------------------\n",
      "Epoch 1500:\n",
      "Train loss: 0.017294272780418396 | Test loss: 0.015134716406464577\n",
      "----------------------------\n",
      "Epoch 1550:\n",
      "Train loss: 0.016842849552631378 | Test loss: 0.014725745655596256\n",
      "----------------------------\n",
      "Epoch 1600:\n",
      "Train loss: 0.016395822167396545 | Test loss: 0.014347654767334461\n",
      "----------------------------\n",
      "Epoch 1650:\n",
      "Train loss: 0.015954026952385902 | Test loss: 0.01395491510629654\n",
      "----------------------------\n",
      "Epoch 1700:\n",
      "Train loss: 0.01551871933043003 | Test loss: 0.013560247607529163\n",
      "----------------------------\n",
      "Epoch 1750:\n",
      "Train loss: 0.01509839203208685 | Test loss: 0.013190031982958317\n",
      "----------------------------\n",
      "Epoch 1800:\n",
      "Train loss: 0.014686538837850094 | Test loss: 0.012828288599848747\n",
      "----------------------------\n",
      "Epoch 1850:\n",
      "Train loss: 0.014280861243605614 | Test loss: 0.01245109923183918\n",
      "----------------------------\n",
      "Epoch 1900:\n",
      "Train loss: 0.01388572994619608 | Test loss: 0.012087181210517883\n",
      "----------------------------\n",
      "Epoch 1950:\n",
      "Train loss: 0.01350117102265358 | Test loss: 0.011751621961593628\n",
      "----------------------------\n",
      "Epoch 2000:\n",
      "Train loss: 0.01312481053173542 | Test loss: 0.011436513625085354\n"
     ]
    }
   ],
   "source": [
    "train_test(model=model3, loss_fn=loss_fn, optimizer=optimizer_3, epochs=2001, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:19.299332274Z",
     "start_time": "2024-07-30T17:03:18.801948855Z"
    }
   },
   "id": "4c30bf9e2e26b5e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's try now with more complicated model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30ebc001f520a21a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_data(X_num, y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:19.316160670Z",
     "start_time": "2024-07-30T17:03:19.296514472Z"
    }
   },
   "id": "bf2afca4710f282b"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class ModelV2(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(in_features=in_features, out_features=10),\n",
    "            nn.Linear(in_features=10, out_features=10),\n",
    "            nn.Linear(in_features=10, out_features=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:19.341547469Z",
     "start_time": "2024-07-30T17:03:19.306520062Z"
    }
   },
   "id": "981238182a99652f"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "model4 = ModelV2(37)\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer_4 = torch.optim.Adam(model4.parameters(), lr=0.01, weight_decay=1e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:19.375891136Z",
     "start_time": "2024-07-30T17:03:19.312378705Z"
    }
   },
   "id": "7e3837a525559f1d"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Epoch 0:\n",
      "Train loss: 182205.359375 | Test loss: 177054.1875\n",
      "----------------------------\n",
      "Epoch 50:\n",
      "Train loss: 47997.8359375 | Test loss: 48034.96875\n",
      "----------------------------\n",
      "Epoch 100:\n",
      "Train loss: 40956.8203125 | Test loss: 40956.19921875\n",
      "----------------------------\n",
      "Epoch 150:\n",
      "Train loss: 33094.8203125 | Test loss: 33707.1796875\n",
      "----------------------------\n",
      "Epoch 200:\n",
      "Train loss: 28126.640625 | Test loss: 30191.05859375\n",
      "----------------------------\n",
      "Epoch 250:\n",
      "Train loss: 27174.7421875 | Test loss: 29409.228515625\n",
      "----------------------------\n",
      "Epoch 300:\n",
      "Train loss: 26952.630859375 | Test loss: 29026.658203125\n",
      "----------------------------\n",
      "Epoch 350:\n",
      "Train loss: 26822.541015625 | Test loss: 28795.314453125\n",
      "----------------------------\n",
      "Epoch 400:\n",
      "Train loss: 26715.044921875 | Test loss: 28538.818359375\n",
      "----------------------------\n",
      "Epoch 450:\n",
      "Train loss: 26634.185546875 | Test loss: 28318.1328125\n",
      "----------------------------\n",
      "Epoch 500:\n",
      "Train loss: 26581.322265625 | Test loss: 28181.3828125\n",
      "----------------------------\n",
      "Epoch 550:\n",
      "Train loss: 26541.84375 | Test loss: 28046.9453125\n",
      "----------------------------\n",
      "Epoch 600:\n",
      "Train loss: 26505.603515625 | Test loss: 27956.369140625\n",
      "----------------------------\n",
      "Epoch 650:\n",
      "Train loss: 26481.326171875 | Test loss: 27925.333984375\n",
      "----------------------------\n",
      "Epoch 700:\n",
      "Train loss: 26460.666015625 | Test loss: 27932.576171875\n",
      "----------------------------\n",
      "Epoch 750:\n",
      "Train loss: 26437.7734375 | Test loss: 27913.083984375\n",
      "----------------------------\n",
      "Epoch 800:\n",
      "Train loss: 26417.595703125 | Test loss: 27902.224609375\n",
      "----------------------------\n",
      "Epoch 850:\n",
      "Train loss: 26395.6171875 | Test loss: 27856.240234375\n",
      "----------------------------\n",
      "Epoch 900:\n",
      "Train loss: 26375.150390625 | Test loss: 27828.140625\n",
      "----------------------------\n",
      "Epoch 950:\n",
      "Train loss: 26350.71484375 | Test loss: 27770.958984375\n",
      "----------------------------\n",
      "Epoch 1000:\n",
      "Train loss: 26327.85546875 | Test loss: 27753.798828125\n",
      "----------------------------\n",
      "Epoch 1050:\n",
      "Train loss: 26298.76171875 | Test loss: 27733.46484375\n",
      "----------------------------\n",
      "Epoch 1100:\n",
      "Train loss: 26272.544921875 | Test loss: 27710.423828125\n",
      "----------------------------\n",
      "Epoch 1150:\n",
      "Train loss: 26248.935546875 | Test loss: 27662.28515625\n",
      "----------------------------\n",
      "Epoch 1200:\n",
      "Train loss: 26210.3828125 | Test loss: 27655.669921875\n",
      "----------------------------\n",
      "Epoch 1250:\n",
      "Train loss: 26180.384765625 | Test loss: 27580.853515625\n",
      "----------------------------\n",
      "Epoch 1300:\n",
      "Train loss: 26140.09375 | Test loss: 27575.267578125\n",
      "----------------------------\n",
      "Epoch 1350:\n",
      "Train loss: 26100.21484375 | Test loss: 27552.66015625\n",
      "----------------------------\n",
      "Epoch 1400:\n",
      "Train loss: 26062.564453125 | Test loss: 27535.263671875\n",
      "----------------------------\n",
      "Epoch 1450:\n",
      "Train loss: 26004.857421875 | Test loss: 27470.591796875\n",
      "----------------------------\n",
      "Epoch 1500:\n",
      "Train loss: 25962.5234375 | Test loss: 27473.072265625\n",
      "----------------------------\n",
      "Epoch 1550:\n",
      "Train loss: 25906.99609375 | Test loss: 27379.0625\n",
      "----------------------------\n",
      "Epoch 1600:\n",
      "Train loss: 25827.337890625 | Test loss: 27330.814453125\n",
      "----------------------------\n",
      "Epoch 1650:\n",
      "Train loss: 25765.787109375 | Test loss: 27268.419921875\n",
      "----------------------------\n",
      "Epoch 1700:\n",
      "Train loss: 25646.798828125 | Test loss: 27135.255859375\n",
      "----------------------------\n",
      "Epoch 1750:\n",
      "Train loss: 25569.16796875 | Test loss: 27013.876953125\n",
      "----------------------------\n",
      "Epoch 1800:\n",
      "Train loss: 25415.056640625 | Test loss: 26838.876953125\n",
      "----------------------------\n",
      "Epoch 1850:\n",
      "Train loss: 25370.171875 | Test loss: 26976.931640625\n",
      "----------------------------\n",
      "Epoch 1900:\n",
      "Train loss: 25160.095703125 | Test loss: 26561.19921875\n",
      "----------------------------\n",
      "Epoch 1950:\n",
      "Train loss: 24922.671875 | Test loss: 26198.646484375\n"
     ]
    }
   ],
   "source": [
    "train_test(model4, loss_fn=loss_fn, optimizer=optimizer_4, epochs=2000, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:03:22.391458436Z",
     "start_time": "2024-07-30T17:03:19.358523157Z"
    }
   },
   "id": "ce6c6da6208f2ba9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's now try using categorical variables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c03ff6501c733923"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "     0    1     2        3    4         5    6    7    8    9   ...   69   70  \\\n0  60.0  3.0  65.0   8450.0  1.0  0.450549  3.0  3.0  0.0  4.0  ...  0.0  0.0   \n1  20.0  3.0  80.0   9600.0  1.0  0.450549  3.0  3.0  0.0  2.0  ...  0.0  0.0   \n2  60.0  3.0  68.0  11250.0  1.0  0.450549  0.0  3.0  0.0  4.0  ...  0.0  0.0   \n3  70.0  3.0  60.0   9550.0  1.0  0.450549  0.0  3.0  0.0  0.0  ...  0.0  0.0   \n4  60.0  3.0  84.0  14260.0  1.0  0.450549  0.0  3.0  0.0  2.0  ...  0.0  0.0   \n\n         71        72        73   74    75      76   77   78  \n0  1.142857  1.427046  1.907407  0.0   2.0  2008.0  8.0  4.0  \n1  1.142857  1.427046  1.907407  0.0   5.0  2007.0  8.0  4.0  \n2  1.142857  1.427046  1.907407  0.0   9.0  2008.0  8.0  4.0  \n3  1.142857  1.427046  1.907407  0.0   2.0  2006.0  8.0  0.0  \n4  1.142857  1.427046  1.907407  0.0  12.0  2008.0  8.0  4.0  \n\n[5 rows x 79 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>69</th>\n      <th>70</th>\n      <th>71</th>\n      <th>72</th>\n      <th>73</th>\n      <th>74</th>\n      <th>75</th>\n      <th>76</th>\n      <th>77</th>\n      <th>78</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60.0</td>\n      <td>3.0</td>\n      <td>65.0</td>\n      <td>8450.0</td>\n      <td>1.0</td>\n      <td>0.450549</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.142857</td>\n      <td>1.427046</td>\n      <td>1.907407</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2008.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>80.0</td>\n      <td>9600.0</td>\n      <td>1.0</td>\n      <td>0.450549</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.142857</td>\n      <td>1.427046</td>\n      <td>1.907407</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>2007.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60.0</td>\n      <td>3.0</td>\n      <td>68.0</td>\n      <td>11250.0</td>\n      <td>1.0</td>\n      <td>0.450549</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.142857</td>\n      <td>1.427046</td>\n      <td>1.907407</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70.0</td>\n      <td>3.0</td>\n      <td>60.0</td>\n      <td>9550.0</td>\n      <td>1.0</td>\n      <td>0.450549</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.142857</td>\n      <td>1.427046</td>\n      <td>1.907407</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2006.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60.0</td>\n      <td>3.0</td>\n      <td>84.0</td>\n      <td>14260.0</td>\n      <td>1.0</td>\n      <td>0.450549</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.142857</td>\n      <td>1.427046</td>\n      <td>1.907407</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>2008.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 79 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "label_X = X.copy()\n",
    "\n",
    "s = (X.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X[object_cols] = ordinal_encoder.fit_transform(X[object_cols])\n",
    "label_X = label_X.drop('Id', axis=1)\n",
    "label_X = pd.DataFrame(my_imputer.fit_transform(label_X))\n",
    "label_X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:22:48.383713027Z",
     "start_time": "2024-07-30T17:22:48.337740710Z"
    }
   },
   "id": "c67f59f200040611"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "16    0.571125\n11    0.527699\n61    0.494664\n45    0.430655\n18    0.409119\n37    0.398195\n3     0.393821\n60    0.369533\n58    0.343536\n29    0.334620\nName: MI Scores, dtype: float64"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_scores_all = make_mi_scores(label_X, y, discrete_features=label_X.columns)\n",
    "mi_scores_all[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:24:36.491906995Z",
     "start_time": "2024-07-30T17:24:34.693603662Z"
    }
   },
   "id": "1cff204df4397bcd"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "useful_data = list(mi_scores_all[mi_scores_all.gt(0.3)].index)\n",
    "label_X = label_X[useful_data]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:30:17.611054295Z",
     "start_time": "2024-07-30T17:30:17.567064743Z"
    }
   },
   "id": "4a0f701befc650a7"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_data(label_X, y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:31:15.774837302Z",
     "start_time": "2024-07-30T17:31:15.734214987Z"
    }
   },
   "id": "6f22e6fcb6e51fce"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "model5 = ModelV2(len(useful_data))\n",
    "optimizer_5 = torch.optim.Adam(params=model5.parameters(), lr=0.02, weight_decay=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:34:02.838595060Z",
     "start_time": "2024-07-30T17:34:02.796119235Z"
    }
   },
   "id": "fac3ade3420abb10"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Epoch 0:\n",
      "Train loss: 182954.359375 | Test loss: 174798.0625\n",
      "----------------------------\n",
      "Epoch 50:\n",
      "Train loss: 52202.23046875 | Test loss: 53017.59765625\n",
      "----------------------------\n",
      "Epoch 100:\n",
      "Train loss: 35237.18359375 | Test loss: 34217.0625\n",
      "----------------------------\n",
      "Epoch 150:\n",
      "Train loss: 28863.908203125 | Test loss: 29209.896484375\n",
      "----------------------------\n",
      "Epoch 200:\n",
      "Train loss: 28679.1484375 | Test loss: 29233.00390625\n",
      "----------------------------\n",
      "Epoch 250:\n",
      "Train loss: 28601.75390625 | Test loss: 29230.91015625\n",
      "----------------------------\n",
      "Epoch 300:\n",
      "Train loss: 28551.373046875 | Test loss: 29231.30859375\n",
      "----------------------------\n",
      "Epoch 350:\n",
      "Train loss: 28492.83203125 | Test loss: 29168.60546875\n",
      "----------------------------\n",
      "Epoch 400:\n",
      "Train loss: 28452.486328125 | Test loss: 29091.44921875\n",
      "----------------------------\n",
      "Epoch 450:\n",
      "Train loss: 28387.71484375 | Test loss: 29106.2421875\n",
      "----------------------------\n",
      "Epoch 500:\n",
      "Train loss: 28365.26953125 | Test loss: 29068.326171875\n",
      "----------------------------\n",
      "Epoch 550:\n",
      "Train loss: 28279.603515625 | Test loss: 28983.876953125\n",
      "----------------------------\n",
      "Epoch 600:\n",
      "Train loss: 28174.359375 | Test loss: 28944.08203125\n",
      "----------------------------\n",
      "Epoch 650:\n",
      "Train loss: 28089.10546875 | Test loss: 28883.935546875\n",
      "----------------------------\n",
      "Epoch 700:\n",
      "Train loss: 27991.71484375 | Test loss: 28882.0078125\n",
      "----------------------------\n",
      "Epoch 750:\n",
      "Train loss: 27888.935546875 | Test loss: 28739.60546875\n",
      "----------------------------\n",
      "Epoch 800:\n",
      "Train loss: 27747.3359375 | Test loss: 28654.810546875\n",
      "----------------------------\n",
      "Epoch 850:\n",
      "Train loss: 27698.220703125 | Test loss: 28682.474609375\n",
      "----------------------------\n",
      "Epoch 900:\n",
      "Train loss: 27477.740234375 | Test loss: 28386.91015625\n",
      "----------------------------\n",
      "Epoch 950:\n",
      "Train loss: 27206.662109375 | Test loss: 28298.396484375\n",
      "----------------------------\n",
      "Epoch 1000:\n",
      "Train loss: 26976.248046875 | Test loss: 28118.330078125\n",
      "----------------------------\n",
      "Epoch 1050:\n",
      "Train loss: 26601.91015625 | Test loss: 27785.89453125\n",
      "----------------------------\n",
      "Epoch 1100:\n",
      "Train loss: 26379.771484375 | Test loss: 28071.44140625\n",
      "----------------------------\n",
      "Epoch 1150:\n",
      "Train loss: 25566.99609375 | Test loss: 27602.884765625\n",
      "----------------------------\n",
      "Epoch 1200:\n",
      "Train loss: 25241.341796875 | Test loss: 26980.4765625\n",
      "----------------------------\n",
      "Epoch 1250:\n",
      "Train loss: 25063.478515625 | Test loss: 26625.69140625\n",
      "----------------------------\n",
      "Epoch 1300:\n",
      "Train loss: 23977.126953125 | Test loss: 26181.458984375\n",
      "----------------------------\n",
      "Epoch 1350:\n",
      "Train loss: 23287.46484375 | Test loss: 25514.08984375\n",
      "----------------------------\n",
      "Epoch 1400:\n",
      "Train loss: 23204.65234375 | Test loss: 26590.607421875\n",
      "----------------------------\n",
      "Epoch 1450:\n",
      "Train loss: 22518.126953125 | Test loss: 25221.685546875\n",
      "----------------------------\n",
      "Epoch 1500:\n",
      "Train loss: 24061.22265625 | Test loss: 26833.50390625\n",
      "----------------------------\n",
      "Epoch 1550:\n",
      "Train loss: 21833.4609375 | Test loss: 24271.677734375\n",
      "----------------------------\n",
      "Epoch 1600:\n",
      "Train loss: 23051.96484375 | Test loss: 25151.0625\n",
      "----------------------------\n",
      "Epoch 1650:\n",
      "Train loss: 23089.84765625 | Test loss: 24469.71484375\n",
      "----------------------------\n",
      "Epoch 1700:\n",
      "Train loss: 21624.828125 | Test loss: 24408.353515625\n",
      "----------------------------\n",
      "Epoch 1750:\n",
      "Train loss: 21854.7578125 | Test loss: 24904.724609375\n",
      "----------------------------\n",
      "Epoch 1800:\n",
      "Train loss: 20950.228515625 | Test loss: 23830.0234375\n",
      "----------------------------\n",
      "Epoch 1850:\n",
      "Train loss: 21075.46484375 | Test loss: 24339.517578125\n",
      "----------------------------\n",
      "Epoch 1900:\n",
      "Train loss: 21170.947265625 | Test loss: 24126.224609375\n",
      "----------------------------\n",
      "Epoch 1950:\n",
      "Train loss: 20965.84765625 | Test loss: 23882.80078125\n",
      "----------------------------\n",
      "Epoch 2000:\n",
      "Train loss: 20848.763671875 | Test loss: 23587.375\n"
     ]
    }
   ],
   "source": [
    "train_test(model5, loss_fn=loss_fn, optimizer=optimizer_5, epochs=2001, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T17:34:05.730591609Z",
     "start_time": "2024-07-30T17:34:02.838427110Z"
    }
   },
   "id": "193c5b02673e34d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "48c814440c0ccf11"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
