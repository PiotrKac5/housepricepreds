{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:24.940764635Z",
     "start_time": "2024-07-30T18:06:24.876929902Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n\n  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n0         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n1         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n2         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n3         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n4         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n\n  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n0       0      2    2008        WD         Normal  \n1       0      5    2007        WD         Normal  \n2       0      9    2008        WD         Normal  \n3       0      2    2006        WD        Abnorml  \n4       0     12    2008        WD         Normal  \n\n[5 rows x 80 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 80 columns</p>\n</div>"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "y = data['SalePrice']\n",
    "X = data.drop('SalePrice', axis=1)\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:25.145329029Z",
     "start_time": "2024-07-30T18:06:24.881394724Z"
    }
   },
   "id": "3f375d6aeed3e16c"
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n0   1          60         65.0     8450            7            5       2003   \n1   2          20         80.0     9600            6            8       1976   \n2   3          60         68.0    11250            7            5       2001   \n3   4          70         60.0     9550            7            5       1915   \n4   5          60         84.0    14260            8            5       2000   \n\n   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  GarageArea  WoodDeckSF  \\\n0          2003       196.0         706  ...         548           0   \n1          1976         0.0         978  ...         460         298   \n2          2002       162.0         486  ...         608           0   \n3          1970         0.0         216  ...         642           0   \n4          2000       350.0         655  ...         836         192   \n\n   OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n0           61              0          0            0         0        0   \n1            0              0          0            0         0        0   \n2           42              0          0            0         0        0   \n3           35            272          0            0         0        0   \n4           84              0          0            0         0        0   \n\n   MoSold  YrSold  \n0       2    2008  \n1       5    2007  \n2       9    2008  \n3       2    2006  \n4      12    2008  \n\n[5 rows x 37 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196.0</td>\n      <td>706</td>\n      <td>...</td>\n      <td>548</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0.0</td>\n      <td>978</td>\n      <td>...</td>\n      <td>460</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162.0</td>\n      <td>486</td>\n      <td>...</td>\n      <td>608</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>216</td>\n      <td>...</td>\n      <td>642</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350.0</td>\n      <td>655</td>\n      <td>...</td>\n      <td>836</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 37 columns</p>\n</div>"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.drop('Id', axis=1)\n",
    "numeric_cols = list(X.select_dtypes(include=np.number).columns)\n",
    "X_num = X[numeric_cols]\n",
    "X_num.columns = X[numeric_cols].columns\n",
    "X_num.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:25.318129236Z",
     "start_time": "2024-07-30T18:06:24.903117678Z"
    }
   },
   "id": "f93d42995bc3b2a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First model will use only numeric values and missing values will be imputed with SimpleImputer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7196d8b03b3bd0e1"
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_imputer = SimpleImputer()\n",
    "\n",
    "def get_train_test_data(X, y, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "    imputed_X_test = pd.DataFrame(my_imputer.transform(X_test))\n",
    "    \n",
    "    imputed_X_train.columns = X_train.columns\n",
    "    imputed_X_test.columns = X_test.columns\n",
    "    \n",
    "    X_train, X_test = imputed_X_train, imputed_X_test\n",
    "    \n",
    "    X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.values, dtype=torch.float32).squeeze()\n",
    "    y_test = torch.tensor(y_test.values, dtype=torch.float32).squeeze()\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:25.320520503Z",
     "start_time": "2024-07-30T18:06:24.958348782Z"
    }
   },
   "id": "6abb294b85f240c3"
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_data(X_num, y, test_size=0.2)\n",
    "X_num = pd.DataFrame(my_imputer.transform(X_num))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:25.320680554Z",
     "start_time": "2024-07-30T18:06:24.958490344Z"
    }
   },
   "id": "1430845137a86db"
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "class ModelV1(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=in_features, out_features=1),\n",
    "            # nn.Linear(in_features=10, out_features=10),\n",
    "            # nn.Linear(in_features=10, out_features=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:25.320774613Z",
     "start_time": "2024-07-30T18:06:24.958543947Z"
    }
   },
   "id": "f33340deaf7665f7"
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "model1 = ModelV1(in_features=37)\n",
    "\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(params=model1.parameters(), lr=0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:25.320840984Z",
     "start_time": "2024-07-30T18:06:24.958585888Z"
    }
   },
   "id": "cfa7ae65ba16ce"
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ -192.6853,  -547.2485,  -160.6722,  ...,  -325.7292,  -633.8361,\n        -2070.7332], grad_fn=<SqueezeBackward0>)"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()\n",
    "y_pred = model1(X_train).squeeze()\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:25.321006025Z",
     "start_time": "2024-07-30T18:06:24.958626493Z"
    }
   },
   "id": "1534193b0b21b3c5"
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "def train_test(model:torch.nn.Module, loss_fn:torch.nn.Module, optimizer:torch.optim.Optimizer, epochs:int, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        y_preds = model(X_train).squeeze()\n",
    "        loss = loss_fn(y_preds, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with (torch.inference_mode()):\n",
    "            test_pred = model(X_test).squeeze()\n",
    "            test_loss = loss_fn(test_pred, y_test)\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"----------------------------\")\n",
    "            print(f\"Epoch {epoch}:\")\n",
    "            print(f\"Train loss: {loss} | Test loss: {test_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:25.321105059Z",
     "start_time": "2024-07-30T18:06:24.958729503Z"
    }
   },
   "id": "99076809838fcd50"
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Epoch 0:\n",
      "Train loss: 182054.453125 | Test loss: 164537.40625\n",
      "----------------------------\n",
      "Epoch 50:\n",
      "Train loss: 58978.8828125 | Test loss: 62964.24609375\n",
      "----------------------------\n",
      "Epoch 100:\n",
      "Train loss: 55311.67578125 | Test loss: 58188.85546875\n",
      "----------------------------\n",
      "Epoch 150:\n",
      "Train loss: 52219.02734375 | Test loss: 54179.3515625\n",
      "----------------------------\n",
      "Epoch 200:\n",
      "Train loss: 49892.57421875 | Test loss: 50916.95703125\n",
      "----------------------------\n",
      "Epoch 250:\n",
      "Train loss: 48090.35546875 | Test loss: 48341.234375\n",
      "----------------------------\n",
      "Epoch 300:\n",
      "Train loss: 46655.13671875 | Test loss: 46175.15625\n",
      "----------------------------\n",
      "Epoch 350:\n",
      "Train loss: 45531.49609375 | Test loss: 44601.70703125\n",
      "----------------------------\n",
      "Epoch 400:\n",
      "Train loss: 44623.20703125 | Test loss: 43383.546875\n",
      "----------------------------\n",
      "Epoch 450:\n",
      "Train loss: 43795.13671875 | Test loss: 42378.08984375\n",
      "----------------------------\n",
      "Epoch 500:\n",
      "Train loss: 43034.15625 | Test loss: 41427.51953125\n",
      "----------------------------\n",
      "Epoch 550:\n",
      "Train loss: 42345.8515625 | Test loss: 40608.234375\n",
      "----------------------------\n",
      "Epoch 600:\n",
      "Train loss: 41694.87109375 | Test loss: 39862.76171875\n",
      "----------------------------\n",
      "Epoch 650:\n",
      "Train loss: 41109.78515625 | Test loss: 39278.19140625\n",
      "----------------------------\n",
      "Epoch 700:\n",
      "Train loss: 40606.390625 | Test loss: 38740.10546875\n",
      "----------------------------\n",
      "Epoch 750:\n",
      "Train loss: 40131.02734375 | Test loss: 38224.171875\n",
      "----------------------------\n",
      "Epoch 800:\n",
      "Train loss: 39669.546875 | Test loss: 37723.2734375\n",
      "----------------------------\n",
      "Epoch 850:\n",
      "Train loss: 39230.5859375 | Test loss: 37248.1640625\n",
      "----------------------------\n",
      "Epoch 900:\n",
      "Train loss: 38806.265625 | Test loss: 36792.77734375\n",
      "----------------------------\n",
      "Epoch 950:\n",
      "Train loss: 38390.1640625 | Test loss: 36343.453125\n",
      "----------------------------\n",
      "Epoch 1000:\n",
      "Train loss: 37985.31640625 | Test loss: 35909.38671875\n",
      "----------------------------\n",
      "Epoch 1050:\n",
      "Train loss: 37587.58203125 | Test loss: 35496.92578125\n",
      "----------------------------\n",
      "Epoch 1100:\n",
      "Train loss: 37201.9296875 | Test loss: 35096.77734375\n",
      "----------------------------\n",
      "Epoch 1150:\n",
      "Train loss: 36836.04296875 | Test loss: 34719.9375\n",
      "----------------------------\n",
      "Epoch 1200:\n",
      "Train loss: 36490.94140625 | Test loss: 34353.8203125\n",
      "----------------------------\n",
      "Epoch 1250:\n",
      "Train loss: 36160.52734375 | Test loss: 33998.06640625\n",
      "----------------------------\n",
      "Epoch 1300:\n",
      "Train loss: 35837.95703125 | Test loss: 33647.74609375\n",
      "----------------------------\n",
      "Epoch 1350:\n",
      "Train loss: 35522.26953125 | Test loss: 33315.6171875\n",
      "----------------------------\n",
      "Epoch 1400:\n",
      "Train loss: 35222.84765625 | Test loss: 32992.5390625\n",
      "----------------------------\n",
      "Epoch 1450:\n",
      "Train loss: 34941.92578125 | Test loss: 32703.326171875\n",
      "----------------------------\n",
      "Epoch 1500:\n",
      "Train loss: 34668.87109375 | Test loss: 32407.63671875\n",
      "----------------------------\n",
      "Epoch 1550:\n",
      "Train loss: 34403.57421875 | Test loss: 32124.923828125\n",
      "----------------------------\n",
      "Epoch 1600:\n",
      "Train loss: 34159.1796875 | Test loss: 31852.376953125\n",
      "----------------------------\n",
      "Epoch 1650:\n",
      "Train loss: 33923.83203125 | Test loss: 31592.787109375\n",
      "----------------------------\n",
      "Epoch 1700:\n",
      "Train loss: 33699.54296875 | Test loss: 31336.017578125\n",
      "----------------------------\n",
      "Epoch 1750:\n",
      "Train loss: 33480.8984375 | Test loss: 31099.0078125\n",
      "----------------------------\n",
      "Epoch 1800:\n",
      "Train loss: 33278.09375 | Test loss: 30868.478515625\n",
      "----------------------------\n",
      "Epoch 1850:\n",
      "Train loss: 33078.8515625 | Test loss: 30651.708984375\n",
      "----------------------------\n",
      "Epoch 1900:\n",
      "Train loss: 32884.84765625 | Test loss: 30412.6875\n",
      "----------------------------\n",
      "Epoch 1950:\n",
      "Train loss: 32703.421875 | Test loss: 30197.404296875\n"
     ]
    }
   ],
   "source": [
    "train_test(model=model1, loss_fn=loss_fn, optimizer=optimizer, epochs=2000, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:25.988577701Z",
     "start_time": "2024-07-30T18:06:24.958775163Z"
    }
   },
   "id": "cf68177afdf2c915"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This results are not great, let's figure out which 5 data columns have the most corelation with SalePrice and use only them"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86fb12508d61e8e5"
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:25.991635375Z",
     "start_time": "2024-07-30T18:06:25.989389387Z"
    }
   },
   "id": "e8e7e783399b8c90"
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "data": {
      "text/plain": "4     0.553254\n16    0.483946\n26    0.374828\n12    0.366776\n27    0.362363\n6     0.358356\n13    0.308175\nName: MI Scores, dtype: float64"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_features = X_num.dtypes == int\n",
    "\n",
    "mi_scores = make_mi_scores(X_num, y, discrete_features=discrete_features)\n",
    "mi_scores[:7]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:26.199073117Z",
     "start_time": "2024-07-30T18:06:25.992674273Z"
    }
   },
   "id": "2e7b7d286e2e9220"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's now use only this 7 features in a Model and see if there is any difference in performance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d35d8f0f804fcc5"
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "model2 = ModelV1(in_features=7)\n",
    "lista = list(mi_scores[:7].index)\n",
    "for i in lista:\n",
    "    i -= 1\n",
    "X_num_2 = X_num[lista]\n",
    "X_train, X_test, y_train, y_test = get_train_test_data(X_num_2, y, test_size=0.2)\n",
    "optimizer_2 = torch.optim.SGD(params=model2.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:26.199421671Z",
     "start_time": "2024-07-30T18:06:26.182133434Z"
    }
   },
   "id": "669c09d2f00993d0"
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Epoch 0:\n",
      "Train loss: 181554.265625 | Test loss: 171862.515625\n",
      "----------------------------\n",
      "Epoch 50:\n",
      "Train loss: 39001.36328125 | Test loss: 36363.30859375\n",
      "----------------------------\n",
      "Epoch 100:\n",
      "Train loss: 37194.98046875 | Test loss: 34653.47265625\n",
      "----------------------------\n",
      "Epoch 150:\n",
      "Train loss: 35792.59375 | Test loss: 33223.70703125\n",
      "----------------------------\n",
      "Epoch 200:\n",
      "Train loss: 34680.41015625 | Test loss: 32105.140625\n",
      "----------------------------\n",
      "Epoch 250:\n",
      "Train loss: 33768.05859375 | Test loss: 31225.986328125\n",
      "----------------------------\n",
      "Epoch 300:\n",
      "Train loss: 32989.5234375 | Test loss: 30568.240234375\n",
      "----------------------------\n",
      "Epoch 350:\n",
      "Train loss: 32415.1171875 | Test loss: 30098.0625\n",
      "----------------------------\n",
      "Epoch 400:\n",
      "Train loss: 32013.185546875 | Test loss: 29715.435546875\n",
      "----------------------------\n",
      "Epoch 450:\n",
      "Train loss: 31716.068359375 | Test loss: 29400.36328125\n",
      "----------------------------\n",
      "Epoch 500:\n",
      "Train loss: 31472.78515625 | Test loss: 29121.609375\n",
      "----------------------------\n",
      "Epoch 550:\n",
      "Train loss: 31266.263671875 | Test loss: 28909.955078125\n",
      "----------------------------\n",
      "Epoch 600:\n",
      "Train loss: 31087.017578125 | Test loss: 28727.712890625\n",
      "----------------------------\n",
      "Epoch 650:\n",
      "Train loss: 30926.49609375 | Test loss: 28566.484375\n",
      "----------------------------\n",
      "Epoch 700:\n",
      "Train loss: 30789.03515625 | Test loss: 28414.765625\n",
      "----------------------------\n",
      "Epoch 750:\n",
      "Train loss: 30677.03125 | Test loss: 28311.408203125\n",
      "----------------------------\n",
      "Epoch 800:\n",
      "Train loss: 30575.88671875 | Test loss: 28211.359375\n",
      "----------------------------\n",
      "Epoch 850:\n",
      "Train loss: 30485.3125 | Test loss: 28120.34765625\n",
      "----------------------------\n",
      "Epoch 900:\n",
      "Train loss: 30401.380859375 | Test loss: 28031.53515625\n",
      "----------------------------\n",
      "Epoch 950:\n",
      "Train loss: 30328.767578125 | Test loss: 27968.107421875\n",
      "----------------------------\n",
      "Epoch 1000:\n",
      "Train loss: 30258.35546875 | Test loss: 27903.86328125\n",
      "----------------------------\n",
      "Epoch 1050:\n",
      "Train loss: 30189.013671875 | Test loss: 27838.642578125\n",
      "----------------------------\n",
      "Epoch 1100:\n",
      "Train loss: 30124.673828125 | Test loss: 27780.640625\n",
      "----------------------------\n",
      "Epoch 1150:\n",
      "Train loss: 30062.16796875 | Test loss: 27732.41015625\n",
      "----------------------------\n",
      "Epoch 1200:\n",
      "Train loss: 30003.1640625 | Test loss: 27682.853515625\n",
      "----------------------------\n",
      "Epoch 1250:\n",
      "Train loss: 29950.349609375 | Test loss: 27638.615234375\n",
      "----------------------------\n",
      "Epoch 1300:\n",
      "Train loss: 29900.02734375 | Test loss: 27599.73828125\n",
      "----------------------------\n",
      "Epoch 1350:\n",
      "Train loss: 29849.869140625 | Test loss: 27550.521484375\n",
      "----------------------------\n",
      "Epoch 1400:\n",
      "Train loss: 29801.376953125 | Test loss: 27512.689453125\n",
      "----------------------------\n",
      "Epoch 1450:\n",
      "Train loss: 29759.0859375 | Test loss: 27487.548828125\n",
      "----------------------------\n",
      "Epoch 1500:\n",
      "Train loss: 29722.5 | Test loss: 27464.552734375\n",
      "----------------------------\n",
      "Epoch 1550:\n",
      "Train loss: 29688.46484375 | Test loss: 27438.791015625\n",
      "----------------------------\n",
      "Epoch 1600:\n",
      "Train loss: 29658.10546875 | Test loss: 27420.671875\n",
      "----------------------------\n",
      "Epoch 1650:\n",
      "Train loss: 29634.287109375 | Test loss: 27404.3125\n",
      "----------------------------\n",
      "Epoch 1700:\n",
      "Train loss: 29613.97265625 | Test loss: 27389.52734375\n",
      "----------------------------\n",
      "Epoch 1750:\n",
      "Train loss: 29594.41796875 | Test loss: 27378.146484375\n",
      "----------------------------\n",
      "Epoch 1800:\n",
      "Train loss: 29576.97265625 | Test loss: 27366.15625\n",
      "----------------------------\n",
      "Epoch 1850:\n",
      "Train loss: 29560.2734375 | Test loss: 27358.41796875\n",
      "----------------------------\n",
      "Epoch 1900:\n",
      "Train loss: 29545.787109375 | Test loss: 27351.8515625\n",
      "----------------------------\n",
      "Epoch 1950:\n",
      "Train loss: 29533.130859375 | Test loss: 27348.55859375\n"
     ]
    }
   ],
   "source": [
    "train_test(model=model2, loss_fn=loss_fn, optimizer=optimizer_2, epochs=2000, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:26.617900848Z",
     "start_time": "2024-07-30T18:06:26.188592140Z"
    }
   },
   "id": "84eeee795b86b4c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now let's try to normalize data and see whether it improves our result or not"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0109b661b6b2c0c"
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "X_num_3 = X_num_2\n",
    "y_normalized = pd.DataFrame(torch.nn.functional.normalize(torch.tensor(y, dtype=torch.float32).unsqueeze(dim=1)))\n",
    "X_train, X_test, y_train, y_test = get_train_test_data(X_num_3, y_normalized, test_size=0.2)\n",
    "X_train, X_test = torch.nn.functional.normalize(X_train), torch.nn.functional.normalize(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:26.618208832Z",
     "start_time": "2024-07-30T18:06:26.609292122Z"
    }
   },
   "id": "35286dbc2acaba91"
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "model3 = ModelV1(in_features=7)\n",
    "optimizer_3 = torch.optim.SGD(params=model3.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:26.658799598Z",
     "start_time": "2024-07-30T18:06:26.616453294Z"
    }
   },
   "id": "2a561fb63a6745c0"
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Epoch 0:\n",
      "Train loss: 1.0369818210601807 | Test loss: 1.0436515808105469\n",
      "----------------------------\n",
      "Epoch 50:\n",
      "Train loss: 0.9388831257820129 | Test loss: 0.9455909132957458\n",
      "----------------------------\n",
      "Epoch 100:\n",
      "Train loss: 0.8407841920852661 | Test loss: 0.8475304245948792\n",
      "----------------------------\n",
      "Epoch 150:\n",
      "Train loss: 0.7426854968070984 | Test loss: 0.7494698762893677\n",
      "----------------------------\n",
      "Epoch 200:\n",
      "Train loss: 0.6445866823196411 | Test loss: 0.6514092683792114\n",
      "----------------------------\n",
      "Epoch 250:\n",
      "Train loss: 0.5464879274368286 | Test loss: 0.5533487796783447\n",
      "----------------------------\n",
      "Epoch 300:\n",
      "Train loss: 0.44839027523994446 | Test loss: 0.4552893340587616\n",
      "----------------------------\n",
      "Epoch 350:\n",
      "Train loss: 0.3502930998802185 | Test loss: 0.35723039507865906\n",
      "----------------------------\n",
      "Epoch 400:\n",
      "Train loss: 0.25219592452049255 | Test loss: 0.25917139649391174\n",
      "----------------------------\n",
      "Epoch 450:\n",
      "Train loss: 0.15414118766784668 | Test loss: 0.16114039719104767\n",
      "----------------------------\n",
      "Epoch 500:\n",
      "Train loss: 0.0718475729227066 | Test loss: 0.07786056399345398\n",
      "----------------------------\n",
      "Epoch 550:\n",
      "Train loss: 0.05162206292152405 | Test loss: 0.054966796189546585\n",
      "----------------------------\n",
      "Epoch 600:\n",
      "Train loss: 0.04917421564459801 | Test loss: 0.05151275917887688\n",
      "----------------------------\n",
      "Epoch 650:\n",
      "Train loss: 0.048427462577819824 | Test loss: 0.050495658069849014\n",
      "----------------------------\n",
      "Epoch 700:\n",
      "Train loss: 0.04788794741034508 | Test loss: 0.049891818314790726\n",
      "----------------------------\n",
      "Epoch 750:\n",
      "Train loss: 0.04735713452100754 | Test loss: 0.049350861459970474\n",
      "----------------------------\n",
      "Epoch 800:\n",
      "Train loss: 0.046826329082250595 | Test loss: 0.048809900879859924\n",
      "----------------------------\n",
      "Epoch 850:\n",
      "Train loss: 0.04629553481936455 | Test loss: 0.048271819949150085\n",
      "----------------------------\n",
      "Epoch 900:\n",
      "Train loss: 0.04576478525996208 | Test loss: 0.04774325713515282\n",
      "----------------------------\n",
      "Epoch 950:\n",
      "Train loss: 0.04523424059152603 | Test loss: 0.04721619933843613\n",
      "----------------------------\n",
      "Epoch 1000:\n",
      "Train loss: 0.04470372572541237 | Test loss: 0.046689629554748535\n",
      "----------------------------\n",
      "Epoch 1050:\n",
      "Train loss: 0.04417319968342781 | Test loss: 0.04616304486989975\n",
      "----------------------------\n",
      "Epoch 1100:\n",
      "Train loss: 0.04364282637834549 | Test loss: 0.045627448707818985\n",
      "----------------------------\n",
      "Epoch 1150:\n",
      "Train loss: 0.04311583191156387 | Test loss: 0.04508893936872482\n",
      "----------------------------\n",
      "Epoch 1200:\n",
      "Train loss: 0.042588941752910614 | Test loss: 0.04455047845840454\n",
      "----------------------------\n",
      "Epoch 1250:\n",
      "Train loss: 0.04206205531954765 | Test loss: 0.04401250556111336\n",
      "----------------------------\n",
      "Epoch 1300:\n",
      "Train loss: 0.041536830365657806 | Test loss: 0.0434749536216259\n",
      "----------------------------\n",
      "Epoch 1350:\n",
      "Train loss: 0.0410136803984642 | Test loss: 0.042945168912410736\n",
      "----------------------------\n",
      "Epoch 1400:\n",
      "Train loss: 0.04049065336585045 | Test loss: 0.042422935366630554\n",
      "----------------------------\n",
      "Epoch 1450:\n",
      "Train loss: 0.039967674762010574 | Test loss: 0.041903719305992126\n",
      "----------------------------\n",
      "Epoch 1500:\n",
      "Train loss: 0.039444755762815475 | Test loss: 0.04138712212443352\n",
      "----------------------------\n",
      "Epoch 1550:\n",
      "Train loss: 0.03892183303833008 | Test loss: 0.04087052121758461\n",
      "----------------------------\n",
      "Epoch 1600:\n",
      "Train loss: 0.03840132802724838 | Test loss: 0.04034678637981415\n",
      "----------------------------\n",
      "Epoch 1650:\n",
      "Train loss: 0.037882544100284576 | Test loss: 0.039820682257413864\n",
      "----------------------------\n",
      "Epoch 1700:\n",
      "Train loss: 0.03736376762390137 | Test loss: 0.0393015593290329\n",
      "----------------------------\n",
      "Epoch 1750:\n",
      "Train loss: 0.03684500977396965 | Test loss: 0.03878291696310043\n",
      "----------------------------\n",
      "Epoch 1800:\n",
      "Train loss: 0.036326415836811066 | Test loss: 0.03826877102255821\n",
      "----------------------------\n",
      "Epoch 1850:\n",
      "Train loss: 0.035807859152555466 | Test loss: 0.037755850702524185\n",
      "----------------------------\n",
      "Epoch 1900:\n",
      "Train loss: 0.035290032625198364 | Test loss: 0.037240538746118546\n",
      "----------------------------\n",
      "Epoch 1950:\n",
      "Train loss: 0.03477979451417923 | Test loss: 0.03672042489051819\n",
      "----------------------------\n",
      "Epoch 2000:\n",
      "Train loss: 0.03427036479115486 | Test loss: 0.03621048480272293\n"
     ]
    }
   ],
   "source": [
    "train_test(model=model3, loss_fn=loss_fn, optimizer=optimizer_3, epochs=2001, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:27.056100043Z",
     "start_time": "2024-07-30T18:06:26.658575173Z"
    }
   },
   "id": "4c30bf9e2e26b5e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's try now with more complicated model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30ebc001f520a21a"
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_data(X_num, y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:27.087381829Z",
     "start_time": "2024-07-30T18:06:27.057235752Z"
    }
   },
   "id": "bf2afca4710f282b"
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "class ModelV2(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(in_features=in_features, out_features=10),\n",
    "            nn.Linear(in_features=10, out_features=10),\n",
    "            nn.Linear(in_features=10, out_features=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:27.087718780Z",
     "start_time": "2024-07-30T18:06:27.062320577Z"
    }
   },
   "id": "981238182a99652f"
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "model4 = ModelV2(37)\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer_4 = torch.optim.Adam(model4.parameters(), lr=0.01, weight_decay=1e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:27.121204480Z",
     "start_time": "2024-07-30T18:06:27.066226315Z"
    }
   },
   "id": "7e3837a525559f1d"
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Epoch 0:\n",
      "Train loss: 181277.515625 | Test loss: 178446.46875\n",
      "----------------------------\n",
      "Epoch 50:\n",
      "Train loss: 49215.9453125 | Test loss: 46153.7265625\n",
      "----------------------------\n",
      "Epoch 100:\n",
      "Train loss: 40684.32421875 | Test loss: 38366.8984375\n",
      "----------------------------\n",
      "Epoch 150:\n",
      "Train loss: 31227.154296875 | Test loss: 31239.13671875\n",
      "----------------------------\n",
      "Epoch 200:\n",
      "Train loss: 27144.28515625 | Test loss: 29595.455078125\n",
      "----------------------------\n",
      "Epoch 250:\n",
      "Train loss: 26596.517578125 | Test loss: 29967.96484375\n",
      "----------------------------\n",
      "Epoch 300:\n",
      "Train loss: 26343.33984375 | Test loss: 29995.9765625\n",
      "----------------------------\n",
      "Epoch 350:\n",
      "Train loss: 26200.548828125 | Test loss: 30019.03125\n",
      "----------------------------\n",
      "Epoch 400:\n",
      "Train loss: 26132.955078125 | Test loss: 29913.46875\n",
      "----------------------------\n",
      "Epoch 450:\n",
      "Train loss: 26088.88671875 | Test loss: 29851.0\n",
      "----------------------------\n",
      "Epoch 500:\n",
      "Train loss: 26050.5078125 | Test loss: 29827.173828125\n",
      "----------------------------\n",
      "Epoch 550:\n",
      "Train loss: 26023.4375 | Test loss: 29828.0078125\n",
      "----------------------------\n",
      "Epoch 600:\n",
      "Train loss: 26001.951171875 | Test loss: 29788.75\n",
      "----------------------------\n",
      "Epoch 650:\n",
      "Train loss: 25983.791015625 | Test loss: 29746.708984375\n",
      "----------------------------\n",
      "Epoch 700:\n",
      "Train loss: 25958.134765625 | Test loss: 29733.240234375\n",
      "----------------------------\n",
      "Epoch 750:\n",
      "Train loss: 25932.048828125 | Test loss: 29678.482421875\n",
      "----------------------------\n",
      "Epoch 800:\n",
      "Train loss: 25907.701171875 | Test loss: 29654.80078125\n",
      "----------------------------\n",
      "Epoch 850:\n",
      "Train loss: 25883.24609375 | Test loss: 29630.28125\n",
      "----------------------------\n",
      "Epoch 900:\n",
      "Train loss: 25857.396484375 | Test loss: 29591.369140625\n",
      "----------------------------\n",
      "Epoch 950:\n",
      "Train loss: 25835.23046875 | Test loss: 29556.037109375\n",
      "----------------------------\n",
      "Epoch 1000:\n",
      "Train loss: 25800.6171875 | Test loss: 29538.958984375\n",
      "----------------------------\n",
      "Epoch 1050:\n",
      "Train loss: 25776.890625 | Test loss: 29475.5234375\n",
      "----------------------------\n",
      "Epoch 1100:\n",
      "Train loss: 25747.630859375 | Test loss: 29443.03125\n",
      "----------------------------\n",
      "Epoch 1150:\n",
      "Train loss: 25704.263671875 | Test loss: 29425.986328125\n",
      "----------------------------\n",
      "Epoch 1200:\n",
      "Train loss: 25674.185546875 | Test loss: 29370.228515625\n",
      "----------------------------\n",
      "Epoch 1250:\n",
      "Train loss: 25628.90234375 | Test loss: 29316.77734375\n",
      "----------------------------\n",
      "Epoch 1300:\n",
      "Train loss: 25582.744140625 | Test loss: 29277.78515625\n",
      "----------------------------\n",
      "Epoch 1350:\n",
      "Train loss: 25535.8828125 | Test loss: 29195.400390625\n",
      "----------------------------\n",
      "Epoch 1400:\n",
      "Train loss: 25482.896484375 | Test loss: 29193.28125\n",
      "----------------------------\n",
      "Epoch 1450:\n",
      "Train loss: 25437.646484375 | Test loss: 29126.591796875\n",
      "----------------------------\n",
      "Epoch 1500:\n",
      "Train loss: 25349.93359375 | Test loss: 29025.4921875\n",
      "----------------------------\n",
      "Epoch 1550:\n",
      "Train loss: 25281.84375 | Test loss: 28923.677734375\n",
      "----------------------------\n",
      "Epoch 1600:\n",
      "Train loss: 25200.3125 | Test loss: 28863.181640625\n",
      "----------------------------\n",
      "Epoch 1650:\n",
      "Train loss: 25106.298828125 | Test loss: 28747.6328125\n",
      "----------------------------\n",
      "Epoch 1700:\n",
      "Train loss: 24966.841796875 | Test loss: 28612.47265625\n",
      "----------------------------\n",
      "Epoch 1750:\n",
      "Train loss: 24891.689453125 | Test loss: 28459.48046875\n",
      "----------------------------\n",
      "Epoch 1800:\n",
      "Train loss: 24792.900390625 | Test loss: 28179.927734375\n",
      "----------------------------\n",
      "Epoch 1850:\n",
      "Train loss: 24529.041015625 | Test loss: 28038.546875\n",
      "----------------------------\n",
      "Epoch 1900:\n",
      "Train loss: 25106.142578125 | Test loss: 27824.16015625\n",
      "----------------------------\n",
      "Epoch 1950:\n",
      "Train loss: 24175.6328125 | Test loss: 27439.71875\n"
     ]
    }
   ],
   "source": [
    "train_test(model4, loss_fn=loss_fn, optimizer=optimizer_4, epochs=2000, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:29.762330080Z",
     "start_time": "2024-07-30T18:06:27.110359658Z"
    }
   },
   "id": "ce6c6da6208f2ba9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's now try using categorical variables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c03ff6501c733923"
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "     0    1     2        3    4         5    6    7    8    9   ...   69   70  \\\n0  60.0  3.0  65.0   8450.0  1.0  0.450549  3.0  3.0  0.0  4.0  ...  0.0  0.0   \n1  20.0  3.0  80.0   9600.0  1.0  0.450549  3.0  3.0  0.0  2.0  ...  0.0  0.0   \n2  60.0  3.0  68.0  11250.0  1.0  0.450549  0.0  3.0  0.0  4.0  ...  0.0  0.0   \n3  70.0  3.0  60.0   9550.0  1.0  0.450549  0.0  3.0  0.0  0.0  ...  0.0  0.0   \n4  60.0  3.0  84.0  14260.0  1.0  0.450549  0.0  3.0  0.0  2.0  ...  0.0  0.0   \n\n         71        72        73   74    75      76   77   78  \n0  1.142857  1.427046  1.907407  0.0   2.0  2008.0  8.0  4.0  \n1  1.142857  1.427046  1.907407  0.0   5.0  2007.0  8.0  4.0  \n2  1.142857  1.427046  1.907407  0.0   9.0  2008.0  8.0  4.0  \n3  1.142857  1.427046  1.907407  0.0   2.0  2006.0  8.0  0.0  \n4  1.142857  1.427046  1.907407  0.0  12.0  2008.0  8.0  4.0  \n\n[5 rows x 79 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>69</th>\n      <th>70</th>\n      <th>71</th>\n      <th>72</th>\n      <th>73</th>\n      <th>74</th>\n      <th>75</th>\n      <th>76</th>\n      <th>77</th>\n      <th>78</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60.0</td>\n      <td>3.0</td>\n      <td>65.0</td>\n      <td>8450.0</td>\n      <td>1.0</td>\n      <td>0.450549</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.142857</td>\n      <td>1.427046</td>\n      <td>1.907407</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2008.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>80.0</td>\n      <td>9600.0</td>\n      <td>1.0</td>\n      <td>0.450549</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.142857</td>\n      <td>1.427046</td>\n      <td>1.907407</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>2007.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60.0</td>\n      <td>3.0</td>\n      <td>68.0</td>\n      <td>11250.0</td>\n      <td>1.0</td>\n      <td>0.450549</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.142857</td>\n      <td>1.427046</td>\n      <td>1.907407</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70.0</td>\n      <td>3.0</td>\n      <td>60.0</td>\n      <td>9550.0</td>\n      <td>1.0</td>\n      <td>0.450549</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.142857</td>\n      <td>1.427046</td>\n      <td>1.907407</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2006.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60.0</td>\n      <td>3.0</td>\n      <td>84.0</td>\n      <td>14260.0</td>\n      <td>1.0</td>\n      <td>0.450549</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.142857</td>\n      <td>1.427046</td>\n      <td>1.907407</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>2008.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 79 columns</p>\n</div>"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "label_X = X.copy()\n",
    "\n",
    "s = (X.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X[object_cols] = ordinal_encoder.fit_transform(X[object_cols])\n",
    "label_X = label_X.drop('Id', axis=1)\n",
    "label_X = pd.DataFrame(my_imputer.fit_transform(label_X))\n",
    "label_X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:29.800626279Z",
     "start_time": "2024-07-30T18:06:29.755470446Z"
    }
   },
   "id": "c67f59f200040611"
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "data": {
      "text/plain": "16    0.572001\n11    0.527917\n61    0.495389\n45    0.433127\n18    0.411872\n37    0.399563\n3     0.393677\n60    0.369847\n58    0.345411\n29    0.334689\nName: MI Scores, dtype: float64"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_scores_all = make_mi_scores(label_X, y, discrete_features=label_X.columns)\n",
    "mi_scores_all[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:31.739552472Z",
     "start_time": "2024-07-30T18:06:29.797218080Z"
    }
   },
   "id": "1cff204df4397bcd"
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "useful_data = list(mi_scores_all[mi_scores_all.gt(0.3)].index)\n",
    "label_X = label_X[useful_data]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:31.767337722Z",
     "start_time": "2024-07-30T18:06:31.743748343Z"
    }
   },
   "id": "4a0f701befc650a7"
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_data(label_X, y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:31.767633109Z",
     "start_time": "2024-07-30T18:06:31.747588585Z"
    }
   },
   "id": "6f22e6fcb6e51fce"
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "model5 = ModelV2(len(useful_data))\n",
    "optimizer_5 = torch.optim.Adam(params=model5.parameters(), lr=0.02, weight_decay=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:31.821234412Z",
     "start_time": "2024-07-30T18:06:31.754858837Z"
    }
   },
   "id": "fac3ade3420abb10"
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Epoch 0:\n",
      "Train loss: 181647.609375 | Test loss: 177688.359375\n",
      "----------------------------\n",
      "Epoch 50:\n",
      "Train loss: 53156.4296875 | Test loss: 51383.34375\n",
      "----------------------------\n",
      "Epoch 100:\n",
      "Train loss: 36323.3828125 | Test loss: 34159.7109375\n",
      "----------------------------\n",
      "Epoch 150:\n",
      "Train loss: 29573.373046875 | Test loss: 28330.23046875\n",
      "----------------------------\n",
      "Epoch 200:\n",
      "Train loss: 28848.2421875 | Test loss: 28545.25\n",
      "----------------------------\n",
      "Epoch 250:\n",
      "Train loss: 28807.2578125 | Test loss: 28413.53515625\n",
      "----------------------------\n",
      "Epoch 300:\n",
      "Train loss: 28753.376953125 | Test loss: 28331.916015625\n",
      "----------------------------\n",
      "Epoch 350:\n",
      "Train loss: 28706.853515625 | Test loss: 28393.091796875\n",
      "----------------------------\n",
      "Epoch 400:\n",
      "Train loss: 28677.408203125 | Test loss: 28504.13671875\n",
      "----------------------------\n",
      "Epoch 450:\n",
      "Train loss: 28609.24609375 | Test loss: 28316.041015625\n",
      "----------------------------\n",
      "Epoch 500:\n",
      "Train loss: 28564.2109375 | Test loss: 28321.97265625\n",
      "----------------------------\n",
      "Epoch 550:\n",
      "Train loss: 28498.919921875 | Test loss: 28463.021484375\n",
      "----------------------------\n",
      "Epoch 600:\n",
      "Train loss: 28468.890625 | Test loss: 28064.91796875\n",
      "----------------------------\n",
      "Epoch 650:\n",
      "Train loss: 28369.689453125 | Test loss: 28262.62890625\n",
      "----------------------------\n",
      "Epoch 700:\n",
      "Train loss: 28301.873046875 | Test loss: 28081.478515625\n",
      "----------------------------\n",
      "Epoch 750:\n",
      "Train loss: 28235.541015625 | Test loss: 28070.939453125\n",
      "----------------------------\n",
      "Epoch 800:\n",
      "Train loss: 28127.904296875 | Test loss: 27840.30859375\n",
      "----------------------------\n",
      "Epoch 850:\n",
      "Train loss: 28033.6171875 | Test loss: 27891.482421875\n",
      "----------------------------\n",
      "Epoch 900:\n",
      "Train loss: 27898.08203125 | Test loss: 27633.78125\n",
      "----------------------------\n",
      "Epoch 950:\n",
      "Train loss: 27798.5859375 | Test loss: 27294.24609375\n",
      "----------------------------\n",
      "Epoch 1000:\n",
      "Train loss: 27778.4921875 | Test loss: 27929.55078125\n",
      "----------------------------\n",
      "Epoch 1050:\n",
      "Train loss: 27475.4296875 | Test loss: 27796.681640625\n",
      "----------------------------\n",
      "Epoch 1100:\n",
      "Train loss: 27443.697265625 | Test loss: 26771.595703125\n",
      "----------------------------\n",
      "Epoch 1150:\n",
      "Train loss: 27069.87890625 | Test loss: 26359.0625\n",
      "----------------------------\n",
      "Epoch 1200:\n",
      "Train loss: 26943.763671875 | Test loss: 26451.205078125\n",
      "----------------------------\n",
      "Epoch 1250:\n",
      "Train loss: 26375.484375 | Test loss: 25776.212890625\n",
      "----------------------------\n",
      "Epoch 1300:\n",
      "Train loss: 26568.39453125 | Test loss: 26231.064453125\n",
      "----------------------------\n",
      "Epoch 1350:\n",
      "Train loss: 25658.96484375 | Test loss: 24648.224609375\n",
      "----------------------------\n",
      "Epoch 1400:\n",
      "Train loss: 25516.4921875 | Test loss: 24032.517578125\n",
      "----------------------------\n",
      "Epoch 1450:\n",
      "Train loss: 24453.2109375 | Test loss: 24210.611328125\n",
      "----------------------------\n",
      "Epoch 1500:\n",
      "Train loss: 23938.14453125 | Test loss: 22723.482421875\n",
      "----------------------------\n",
      "Epoch 1550:\n",
      "Train loss: 24432.291015625 | Test loss: 23821.3828125\n",
      "----------------------------\n",
      "Epoch 1600:\n",
      "Train loss: 24156.849609375 | Test loss: 21796.603515625\n",
      "----------------------------\n",
      "Epoch 1650:\n",
      "Train loss: 23950.646484375 | Test loss: 23028.048828125\n",
      "----------------------------\n",
      "Epoch 1700:\n",
      "Train loss: 24286.775390625 | Test loss: 21659.8359375\n",
      "----------------------------\n",
      "Epoch 1750:\n",
      "Train loss: 22666.21484375 | Test loss: 21836.93359375\n",
      "----------------------------\n",
      "Epoch 1800:\n",
      "Train loss: 24118.326171875 | Test loss: 24768.19140625\n",
      "----------------------------\n",
      "Epoch 1850:\n",
      "Train loss: 21992.39453125 | Test loss: 20341.5859375\n",
      "----------------------------\n",
      "Epoch 1900:\n",
      "Train loss: 21913.662109375 | Test loss: 20369.78515625\n",
      "----------------------------\n",
      "Epoch 1950:\n",
      "Train loss: 22327.0234375 | Test loss: 20634.96875\n",
      "----------------------------\n",
      "Epoch 2000:\n",
      "Train loss: 21714.833984375 | Test loss: 20175.482421875\n"
     ]
    }
   ],
   "source": [
    "train_test(model5, loss_fn=loss_fn, optimizer=optimizer_5, epochs=2001, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:06:33.488227109Z",
     "start_time": "2024-07-30T18:06:31.802396767Z"
    }
   },
   "id": "193c5b02673e34d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now let's make some predictions and see what score this model gets in competition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4df3e38134177ac9"
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "data": {
      "text/plain": "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n1454  2915         160       RM         21.0     1936   Pave   NaN      Reg   \n1455  2916         160       RM         21.0     1894   Pave   NaN      Reg   \n1456  2917          20       RL        160.0    20000   Pave   NaN      Reg   \n1457  2918          85       RL         62.0    10441   Pave   NaN      Reg   \n1458  2919          60       RL         74.0     9627   Pave   NaN      Reg   \n\n     LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence  \\\n1454         Lvl    AllPub  ...           0        0    NaN    NaN   \n1455         Lvl    AllPub  ...           0        0    NaN    NaN   \n1456         Lvl    AllPub  ...           0        0    NaN    NaN   \n1457         Lvl    AllPub  ...           0        0    NaN  MnPrv   \n1458         Lvl    AllPub  ...           0        0    NaN    NaN   \n\n     MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n1454         NaN       0      6    2006        WD         Normal  \n1455         NaN       0      4    2006        WD        Abnorml  \n1456         NaN       0      9    2006        WD        Abnorml  \n1457        Shed     700      7    2006        WD         Normal  \n1458         NaN       0     11    2006        WD         Normal  \n\n[5 rows x 80 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1454</th>\n      <td>2915</td>\n      <td>160</td>\n      <td>RM</td>\n      <td>21.0</td>\n      <td>1936</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>2916</td>\n      <td>160</td>\n      <td>RM</td>\n      <td>21.0</td>\n      <td>1894</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>2917</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>160.0</td>\n      <td>20000</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>2918</td>\n      <td>85</td>\n      <td>RL</td>\n      <td>62.0</td>\n      <td>10441</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>Shed</td>\n      <td>700</td>\n      <td>7</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>2919</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>74.0</td>\n      <td>9627</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 80 columns</p>\n</div>"
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_eval = pd.read_csv(\"test.csv\")\n",
    "X_eval.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:23:50.093692176Z",
     "start_time": "2024-07-30T18:23:50.042957092Z"
    }
   },
   "id": "2babbde344368619"
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "data": {
      "text/plain": "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n\n  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n\n  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n0       0      6    2010        WD         Normal  \n1   12500      6    2010        WD         Normal  \n2       0      3    2010        WD         Normal  \n3       0      6    2010        WD         Normal  \n4       0      1    2010        WD         Normal  \n\n[5 rows x 80 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1461</td>\n      <td>20</td>\n      <td>RH</td>\n      <td>80.0</td>\n      <td>11622</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>120</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1462</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>81.0</td>\n      <td>14267</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Gar2</td>\n      <td>12500</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1463</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>74.0</td>\n      <td>13830</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1464</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>78.0</td>\n      <td>9978</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1465</td>\n      <td>120</td>\n      <td>RL</td>\n      <td>43.0</td>\n      <td>5005</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>HLS</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>144</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 80 columns</p>\n</div>"
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_X_test = X_eval.copy()\n",
    "label_X_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:30:56.864749457Z",
     "start_time": "2024-07-30T18:30:56.851321575Z"
    }
   },
   "id": "32e789354a08b535"
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "data": {
      "text/plain": "      0    1     2        3    4         5    6    7    8    9   ...     69  \\\n0   20.0  2.0  80.0  11622.0  1.0  0.345794  3.0  3.0  0.0  4.0  ...  120.0   \n1   20.0  3.0  81.0  14267.0  1.0  0.345794  0.0  3.0  0.0  0.0  ...    0.0   \n2   60.0  3.0  74.0  13830.0  1.0  0.345794  0.0  3.0  0.0  4.0  ...    0.0   \n3   60.0  3.0  78.0   9978.0  1.0  0.345794  0.0  3.0  0.0  4.0  ...    0.0   \n4  120.0  3.0  43.0   5005.0  1.0  0.345794  0.0  1.0  0.0  4.0  ...  144.0   \n\n    70        71        72        73       74   75      76   77   78  \n0  0.0  0.333333  2.000000  1.843137      0.0  6.0  2010.0  8.0  4.0  \n1  0.0  0.333333  1.396552  0.000000  12500.0  6.0  2010.0  8.0  4.0  \n2  0.0  0.333333  2.000000  1.843137      0.0  3.0  2010.0  8.0  4.0  \n3  0.0  0.333333  1.396552  1.843137      0.0  6.0  2010.0  8.0  4.0  \n4  0.0  0.333333  1.396552  1.843137      0.0  1.0  2010.0  8.0  4.0  \n\n[5 rows x 79 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>69</th>\n      <th>70</th>\n      <th>71</th>\n      <th>72</th>\n      <th>73</th>\n      <th>74</th>\n      <th>75</th>\n      <th>76</th>\n      <th>77</th>\n      <th>78</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20.0</td>\n      <td>2.0</td>\n      <td>80.0</td>\n      <td>11622.0</td>\n      <td>1.0</td>\n      <td>0.345794</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>120.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>2.000000</td>\n      <td>1.843137</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>2010.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>81.0</td>\n      <td>14267.0</td>\n      <td>1.0</td>\n      <td>0.345794</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>1.396552</td>\n      <td>0.000000</td>\n      <td>12500.0</td>\n      <td>6.0</td>\n      <td>2010.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60.0</td>\n      <td>3.0</td>\n      <td>74.0</td>\n      <td>13830.0</td>\n      <td>1.0</td>\n      <td>0.345794</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>2.000000</td>\n      <td>1.843137</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>2010.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>60.0</td>\n      <td>3.0</td>\n      <td>78.0</td>\n      <td>9978.0</td>\n      <td>1.0</td>\n      <td>0.345794</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>1.396552</td>\n      <td>1.843137</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>2010.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>120.0</td>\n      <td>3.0</td>\n      <td>43.0</td>\n      <td>5005.0</td>\n      <td>1.0</td>\n      <td>0.345794</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>144.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>1.396552</td>\n      <td>1.843137</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2010.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 79 columns</p>\n</div>"
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_X_test = label_X_test.drop(\"Id\", axis=1)\n",
    "\n",
    "label_X_test[object_cols] = ordinal_encoder.fit_transform(label_X_test[object_cols])\n",
    "label_X_test = pd.DataFrame(my_imputer.fit_transform(label_X_test))\n",
    "\n",
    "label_X_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:30:57.219770523Z",
     "start_time": "2024-07-30T18:30:57.174413182Z"
    }
   },
   "id": "9eaca9cdb6452f33"
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "label_X_test = torch.tensor(label_X_test[useful_data].values, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:31:00.832743374Z",
     "start_time": "2024-07-30T18:31:00.820479122Z"
    }
   },
   "id": "3220048d901add6c"
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1459, 12])"
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_X_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:31:02.702408329Z",
     "start_time": "2024-07-30T18:31:02.697193966Z"
    }
   },
   "id": "e977de978b75b11d"
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[127283.76],\n       [166482.7 ],\n       [169461.05],\n       ...,\n       [159634.78],\n       [110707.25],\n       [212968.14]], dtype=float32)"
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.eval()\n",
    "y_res = model5(label_X_test)\n",
    "predictions = y_res.detach().numpy()\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:31:05.827532093Z",
     "start_time": "2024-07-30T18:31:05.816613576Z"
    }
   },
   "id": "159b01315be2d4cb"
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [
    "import csv\n",
    "def write_to_csv(predictions):\n",
    "    with open(\"predicts.csv\", mode=\"w\") as f:\n",
    "        fieldnames = [\n",
    "            \"Id\",\n",
    "            \"SalePrice\"\n",
    "        ]\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for i in range(0, len(predictions)):\n",
    "            dct = {\"Id\":i+1461, \"SalePrice\":predictions[i][0]}\n",
    "            writer.writerow(dct)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:31:13.941678372Z",
     "start_time": "2024-07-30T18:31:13.927188414Z"
    }
   },
   "id": "4bdf2d5bed7f5b1b"
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "write_to_csv(predictions=predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:31:15.658379880Z",
     "start_time": "2024-07-30T18:31:15.653318527Z"
    }
   },
   "id": "b7bb57fcb0c4890"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This model has achieved score of 0.18712 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ca2318432f4f96b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "655011f448275164"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
